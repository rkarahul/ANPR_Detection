{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: nivida\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA5xA_L4_4qn",
        "outputId": "604dbffb-9046-41ee-9854-8c51cc5265dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 15 07:10:11 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ5qdaSCto_Y",
        "outputId": "6ecde8db-6953-4ff1-cc33-5a846fd10679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: /content/recg.zip unzip\n",
        "\n",
        "!unzip /content/recg.zip -d /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnWEi-Dlt90m",
        "outputId": "cad12bd2-7b61-4917-e3c7-500f5ea45124"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/recg.zip\n",
            "   creating: /content/recg/\n",
            "   creating: /content/recg/en_PP-OCRv3_rec/\n",
            "  inflating: /content/recg/en_PP-OCRv3_rec/inference.pdiparams  \n",
            "  inflating: /content/recg/en_PP-OCRv3_rec/inference.pdiparams.info  \n",
            "  inflating: /content/recg/en_PP-OCRv3_rec/inference.pdmodel  \n",
            "  inflating: /content/recg/en_PP-OCRv3_rec/inference.yml  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddlepaddle-gpu   # for using  GPU\n",
        "# !pip install paddlepaddle  # for using  CPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfZVs2HG_0s-",
        "outputId": "98f26656-f0a8-435f-db8c-f337abb2952a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting paddlepaddle-gpu\n",
            "  Downloading paddlepaddle_gpu-2.6.2-cp310-cp310-manylinux1_x86_64.whl.metadata (8.6 kB)\n",
            "Collecting httpx (from paddlepaddle-gpu)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu) (10.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu) (4.4.2)\n",
            "Collecting astor (from paddlepaddle-gpu)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting opt-einsum==3.3.0 (from paddlepaddle-gpu)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu) (3.20.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx->paddlepaddle-gpu)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->paddlepaddle-gpu)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->paddlepaddle-gpu) (1.2.2)\n",
            "Downloading paddlepaddle_gpu-2.6.2-cp310-cp310-manylinux1_x86_64.whl (758.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m758.9/758.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opt-einsum, h11, astor, httpcore, httpx, paddlepaddle-gpu\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "Successfully installed astor-0.8.1 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 opt-einsum-3.3.0 paddlepaddle-gpu-2.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PaddlePaddle==2.6.0\n",
        "!pip install onnxruntime>=1.10.0\n",
        "!pip install paddle2onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1Vwy-vcAADu",
        "outputId": "69f2ae51-9169-41c6-ad58-d5c1b896542a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PaddlePaddle==2.6.0\n",
            "  Downloading paddlepaddle-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from PaddlePaddle==2.6.0) (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from PaddlePaddle==2.6.0) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from PaddlePaddle==2.6.0) (10.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from PaddlePaddle==2.6.0) (4.4.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from PaddlePaddle==2.6.0) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from PaddlePaddle==2.6.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from PaddlePaddle==2.6.0) (3.20.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->PaddlePaddle==2.6.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->PaddlePaddle==2.6.0) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->PaddlePaddle==2.6.0) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->PaddlePaddle==2.6.0) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->PaddlePaddle==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->PaddlePaddle==2.6.0) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->PaddlePaddle==2.6.0) (1.2.2)\n",
            "Downloading paddlepaddle-2.6.0-cp310-cp310-manylinux1_x86_64.whl (125.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PaddlePaddle\n",
            "Successfully installed PaddlePaddle-2.6.0\n",
            "Collecting paddle2onnx\n",
            "  Downloading paddle2onnx-1.2.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Downloading paddle2onnx-1.2.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: paddle2onnx\n",
            "Successfully installed paddle2onnx-1.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: paddle2onnx --model_dir \"D:\\plaza_dataset\\dataset\\paddle_train\\PaddleOCR\\recg\\en_PP-OCRv3_rec\" --model_filename \"D:\\plaza_dataset\\dataset\\paddle_train\\PaddleOCR\\recg\\en_PP-OCRv3_rec\\inference.pdmodel\" --params_filename \"D:\\plaza_dataset\\dataset\\paddle_train\\PaddleOCR\\recg\\en_PP-OCRv3_rec\\inference.pdiparams\" --save_file \"D:\\plaza_dataset\\dataset\\paddle_train\\PaddleOCR\\recg\\en_PP-OCRv3_rec\\model.on\n",
        "\n",
        "!paddle2onnx --model_dir \"/content/recg/en_PP-OCRv3_rec\" --model_filename \"/content/recg/en_PP-OCRv3_rec/inference.pdmodel\" --params_filename \"/content/recg/en_PP-OCRv3_rec/inference.pdiparams\" --save_file \"/content/recg/en_PP-OCRv3_rec/model.onnx\" --opset_version 18\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0FgmS8iv4Eu",
        "outputId": "7a6c0c0e-ea3b-496e-9c1a-3b56d2a34af7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Paddle2ONNX] Start to parse PaddlePaddle model...\n",
            "[Paddle2ONNX] Model file path: /content/recg/en_PP-OCRv3_rec/inference.pdmodel\n",
            "[Paddle2ONNX] Parameters file path: /content/recg/en_PP-OCRv3_rec/inference.pdiparams\n",
            "[Paddle2ONNX] Start to parsing Paddle model...\n",
            "[Paddle2ONNX] Use opset_version = 18 for ONNX export.\n",
            "[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\n"
          ]
        }
      ]
    }
  ]
}